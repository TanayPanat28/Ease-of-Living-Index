{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import miceforest as mf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country                     0.00\n",
      "Year                        0.00\n",
      "Control_of_Corruption       4.01\n",
      "Government_Effectiveness    4.48\n",
      "Political_Stability         3.31\n",
      "Regulatory_Quality          4.44\n",
      "Rule_of_Law                 2.26\n",
      "Voice_and_Accountability    3.13\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Institutional_data_full.csv\")\n",
    "data.replace(\"..\", np.nan, inplace=True)\n",
    "missing_data_percentage = (data.isna().mean() * 100).round(2)\n",
    "print(missing_data_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have very less missing vlaues in all the columns, we will just drop these from the columns and use that as our original dataset and then create the synthetic dataset from that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = data[['Control_of_Corruption','Government_Effectiveness','Political_Stability','Regulatory_Quality',\n",
    "                'Rule_of_Law','Voice_and_Accountability']].dropna()\n",
    "\n",
    "base_data.to_csv(\"synthetic_data_institution_full.csv\",index = False)\n",
    "\n",
    "np.random.seed(76)\n",
    "remove_percentage = 0.3\n",
    "\n",
    "total_values = base_data.shape[0]\n",
    "num_values_to_remove = int(remove_percentage * total_values)\n",
    "\n",
    "nan_indices_Control_of_Corruption = np.random.choice(base_data.index, num_values_to_remove, replace=False)\n",
    "nan_indices_Government_Effectiveness = np.random.choice(base_data.index, num_values_to_remove, replace=False)\n",
    "nan_indices_Political_Stability = np.random.choice(base_data.index, num_values_to_remove, replace=False)\n",
    "nan_indices_Regulatory_Quality = np.random.choice(base_data.index, num_values_to_remove, replace=False)\n",
    "nan_indices_Rule_of_Law = np.random.choice(base_data.index, num_values_to_remove, replace=False)\n",
    "nan_indices_Voice_and_Accountability = np.random.choice(base_data.index, num_values_to_remove, replace=False)\n",
    "\n",
    "base_data.loc[nan_indices_Control_of_Corruption, 'Control_of_Corruption'] = np.nan\n",
    "base_data.loc[nan_indices_Government_Effectiveness, 'Government_Effectiveness'] = np.nan\n",
    "base_data.loc[nan_indices_Political_Stability, 'Political_Stability'] = np.nan\n",
    "base_data.loc[nan_indices_Regulatory_Quality, 'Regulatory_Quality'] = np.nan\n",
    "base_data.loc[nan_indices_Rule_of_Law, 'Rule_of_Law'] = np.nan\n",
    "base_data.loc[nan_indices_Voice_and_Accountability, 'Voice_and_Accountability'] = np.nan\n",
    "\n",
    "base_data.to_csv(\"synthetic_data_institution.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Control_of_Corruption</th>\n",
       "      <th>Government_Effectiveness</th>\n",
       "      <th>Political_Stability</th>\n",
       "      <th>Regulatory_Quality</th>\n",
       "      <th>Rule_of_Law</th>\n",
       "      <th>Voice_and_Accountability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boosting</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_sample_strategy</th>\n",
       "      <td>bagging</td>\n",
       "      <td>bagging</td>\n",
       "      <td>bagging</td>\n",
       "      <td>bagging</td>\n",
       "      <td>bagging</td>\n",
       "      <td>bagging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_iterations</th>\n",
       "      <td>341</td>\n",
       "      <td>312</td>\n",
       "      <td>278</td>\n",
       "      <td>500</td>\n",
       "      <td>378</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_sum_hessian_in_leaf</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_gain_to_split</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging_fraction</th>\n",
       "      <td>0.999136</td>\n",
       "      <td>0.501521</td>\n",
       "      <td>0.307914</td>\n",
       "      <td>0.795465</td>\n",
       "      <td>0.484219</td>\n",
       "      <td>0.989755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_fraction_bynode</th>\n",
       "      <td>0.31248</td>\n",
       "      <td>0.299912</td>\n",
       "      <td>0.580104</td>\n",
       "      <td>0.237637</td>\n",
       "      <td>0.776686</td>\n",
       "      <td>0.621771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging_freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbosity</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>regression</td>\n",
       "      <td>regression</td>\n",
       "      <td>regression</td>\n",
       "      <td>regression</td>\n",
       "      <td>regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Control_of_Corruption Government_Effectiveness  \\\n",
       "boosting                                 gbdt                     gbdt   \n",
       "data_sample_strategy                  bagging                  bagging   \n",
       "num_iterations                            341                      312   \n",
       "max_depth                                   5                        4   \n",
       "num_leaves                                 23                       17   \n",
       "min_data_in_leaf                            2                        6   \n",
       "min_sum_hessian_in_leaf                  0.01                     0.01   \n",
       "min_gain_to_split                         0.0                      0.0   \n",
       "bagging_fraction                     0.999136                 0.501521   \n",
       "feature_fraction_bynode               0.31248                 0.299912   \n",
       "bagging_freq                                1                        1   \n",
       "verbosity                                  -1                       -1   \n",
       "learning_rate                            0.02                     0.02   \n",
       "objective                          regression               regression   \n",
       "\n",
       "                        Political_Stability Regulatory_Quality Rule_of_Law  \\\n",
       "boosting                               gbdt               gbdt        gbdt   \n",
       "data_sample_strategy                bagging            bagging     bagging   \n",
       "num_iterations                          278                500         378   \n",
       "max_depth                                 4                  5           3   \n",
       "num_leaves                               24                 19          18   \n",
       "min_data_in_leaf                          5                  7          54   \n",
       "min_sum_hessian_in_leaf                0.01               0.01        0.01   \n",
       "min_gain_to_split                       0.0                0.0         0.0   \n",
       "bagging_fraction                   0.307914           0.795465    0.484219   \n",
       "feature_fraction_bynode            0.580104           0.237637    0.776686   \n",
       "bagging_freq                              1                  1           1   \n",
       "verbosity                                -1                 -1          -1   \n",
       "learning_rate                          0.02               0.02        0.02   \n",
       "objective                        regression         regression  regression   \n",
       "\n",
       "                        Voice_and_Accountability  \n",
       "boosting                                    gbdt  \n",
       "data_sample_strategy                     bagging  \n",
       "num_iterations                               236  \n",
       "max_depth                                      4  \n",
       "num_leaves                                    15  \n",
       "min_data_in_leaf                               7  \n",
       "min_sum_hessian_in_leaf                     0.01  \n",
       "min_gain_to_split                            0.0  \n",
       "bagging_fraction                        0.989755  \n",
       "feature_fraction_bynode                 0.621771  \n",
       "bagging_freq                                   1  \n",
       "verbosity                                     -1  \n",
       "learning_rate                               0.02  \n",
       "objective                             regression  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_imputation = pd.read_csv(\"synthetic_data_institution.csv\")\n",
    "\n",
    "kernel = mf.ImputationKernel(\n",
    "    data_imputation,\n",
    "    num_datasets = 1,\n",
    "    mean_match_candidates=0,\n",
    "    random_state = 28\n",
    "    )\n",
    "\n",
    "optimal_params = kernel.tune_parameters(\n",
    "    dataset=0, \n",
    "    use_gbdt=True,\n",
    "    num_iterations=500,\n",
    "    random_state=1,\n",
    ")\n",
    "kernel.mice(1, variable_parameters=optimal_params)\n",
    "pd.DataFrame(optimal_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.mice(30,variable_parameters=optimal_params)\n",
    "imputed_data = kernel.complete_data(0)\n",
    "\n",
    "imputed_data.to_csv(\"synthetic_data_institution_imputed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Scores:\n",
      "{'Control_of_Corruption': 0.97, 'Government_Effectiveness': 0.97, 'Political_Stability': 0.91, 'Regulatory_Quality': 0.96, 'Rule_of_Law': 0.98, 'Voice_and_Accountability': 0.92}\n",
      "\n",
      "RMSE Scores:\n",
      "{'Control_of_Corruption': 0.16, 'Government_Effectiveness': 0.16, 'Political_Stability': 0.3, 'Regulatory_Quality': 0.19, 'Rule_of_Law': 0.15, 'Voice_and_Accountability': 0.29}\n",
      "\n",
      "MAE Scores:\n",
      "{'Control_of_Corruption': 0.07, 'Government_Effectiveness': 0.07, 'Political_Stability': 0.12, 'Regulatory_Quality': 0.08, 'Rule_of_Law': 0.06, 'Voice_and_Accountability': 0.12}\n"
     ]
    }
   ],
   "source": [
    "synthetic_data_full = pd.read_csv('synthetic_data_institution_full.csv')\n",
    "imputed_synthetic_data = pd.read_csv('synthetic_data_institution_imputed.csv')\n",
    "\n",
    "columns_to_evaluate = ['Control_of_Corruption','Government_Effectiveness','Political_Stability','Regulatory_Quality',\n",
    "                'Rule_of_Law','Voice_and_Accountability']\n",
    "\n",
    "\n",
    "r2_results = {}\n",
    "rmse_results = {}\n",
    "mae_results = {}\n",
    "\n",
    "for column in columns_to_evaluate:\n",
    "    original_values = synthetic_data_full[column]\n",
    "    imputed_values = imputed_synthetic_data[column]\n",
    "\n",
    "    missing_indices = original_values.isna()\n",
    "    original_values_non_missing = original_values[~missing_indices]\n",
    "    imputed_values_non_missing = imputed_values[~missing_indices]\n",
    "\n",
    "    r2 = r2_score(original_values_non_missing, imputed_values_non_missing)\n",
    "    r2_results[column] = round(r2, 2)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(original_values_non_missing, imputed_values_non_missing))\n",
    "    rmse_results[column] = round(rmse, 2)\n",
    "\n",
    "    mae = mean_absolute_error(original_values_non_missing, imputed_values_non_missing)\n",
    "    mae_results[column] = round(mae, 2)\n",
    "\n",
    "print(\"R² Scores:\")\n",
    "print(r2_results)\n",
    "\n",
    "print(\"\\nRMSE Scores:\")\n",
    "print(rmse_results)\n",
    "\n",
    "print(\"\\nMAE Scores:\")\n",
    "print(mae_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Metric                    Column  Mean Value  Standard Deviation\n",
      "0      R²     Control_of_Corruption        0.90              0.0056\n",
      "1    RMSE     Control_of_Corruption        0.32              0.0087\n",
      "2     MAE     Control_of_Corruption        0.13              0.0033\n",
      "3      R²  Government_Effectiveness        0.89              0.0054\n",
      "4    RMSE  Government_Effectiveness        0.32              0.0084\n",
      "5     MAE  Government_Effectiveness        0.13              0.0026\n",
      "6      R²       Political_Stability        0.78              0.0097\n",
      "7    RMSE       Political_Stability        0.46              0.0105\n",
      "8     MAE       Political_Stability        0.19              0.0043\n",
      "9      R²        Regulatory_Quality        0.87              0.0058\n",
      "10   RMSE        Regulatory_Quality        0.35              0.0082\n",
      "11    MAE        Regulatory_Quality        0.14              0.0031\n",
      "12     R²               Rule_of_Law        0.91              0.0054\n",
      "13   RMSE               Rule_of_Law        0.30              0.0089\n",
      "14    MAE               Rule_of_Law        0.12              0.0033\n",
      "15     R²  Voice_and_Accountability        0.81              0.0061\n",
      "16   RMSE  Voice_and_Accountability        0.44              0.0070\n",
      "17    MAE  Voice_and_Accountability        0.18              0.0031\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "original_data = pd.read_csv('synthetic_data_institution_full.csv')\n",
    "\n",
    "columns_to_evaluate = ['Control_of_Corruption', 'Government_Effectiveness', 'Political_Stability', \n",
    "                       'Regulatory_Quality', 'Rule_of_Law', 'Voice_and_Accountability']\n",
    "\n",
    "# Initialize dictionaries to store metrics across iterations\n",
    "r2_results = {col: [] for col in columns_to_evaluate}\n",
    "rmse_results = {col: [] for col in columns_to_evaluate}\n",
    "mae_results = {col: [] for col in columns_to_evaluate}\n",
    "\n",
    "# Parameters for random NaN generation\n",
    "remove_percentage = 0.3\n",
    "num_iterations = 30\n",
    "\n",
    "# Optimal parameters for miceforest\n",
    "optimal_params = {\n",
    "    # Define optimal parameters here\n",
    "}\n",
    "\n",
    "# Run the evaluation over multiple iterations with random NaN values\n",
    "for i in range(num_iterations):\n",
    "    # Create a new copy of the data to introduce NaN values each time\n",
    "    data = original_data.copy()\n",
    "    \n",
    "    # Randomly introduce NaN values in each column for each iteration\n",
    "    for column in columns_to_evaluate:\n",
    "        num_missing = int(remove_percentage * data[column].dropna().shape[0])\n",
    "        nan_indices = random.sample(list(data[column].dropna().index), num_missing)\n",
    "        data.loc[nan_indices, column] = np.nan\n",
    "    \n",
    "    # Initialize the MICE kernel and perform imputation with optimal parameters\n",
    "    kernel = mf.ImputationKernel(data, num_datasets=1, random_state=34)\n",
    "    kernel.mice(1, variable_parameters=optimal_params)\n",
    "    \n",
    "    # Complete the dataset and save it\n",
    "    imputed_data = kernel.complete_data(0)\n",
    "    imputed_data.to_csv(\"synthetic_data_institution_imputed.csv\", index=False)\n",
    "    \n",
    "    # Calculate metrics for each column\n",
    "    for column in columns_to_evaluate:\n",
    "        original_values = original_data[column]\n",
    "        imputed_values = imputed_data[column]\n",
    "\n",
    "        # Identify non-missing indices in the original dataset\n",
    "        missing_indices = original_values.isna()\n",
    "        original_values_non_missing = original_values[~missing_indices]\n",
    "        imputed_values_non_missing = imputed_values[~missing_indices]\n",
    "\n",
    "        # R² score\n",
    "        r2 = r2_score(original_values_non_missing, imputed_values_non_missing)\n",
    "        r2_results[column].append(r2)\n",
    "\n",
    "        # RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(original_values_non_missing, imputed_values_non_missing))\n",
    "        rmse_results[column].append(rmse)\n",
    "\n",
    "        # MAE\n",
    "        mae = mean_absolute_error(original_values_non_missing, imputed_values_non_missing)\n",
    "        mae_results[column].append(mae)\n",
    "\n",
    "# Calculate mean and standard deviation of metrics across iterations\n",
    "metrics_summary = {\n",
    "    \"Metric\": [],\n",
    "    \"Column\": [],\n",
    "    \"Mean Value\": [],\n",
    "    \"Standard Deviation\": []\n",
    "}\n",
    "\n",
    "# Aggregate results for R², RMSE, and MAE\n",
    "for column in columns_to_evaluate:\n",
    "    for metric, values_dict in zip([\"R²\", \"RMSE\", \"MAE\"], [r2_results, rmse_results, mae_results]):\n",
    "        mean_val = np.mean(values_dict[column])\n",
    "        std_dev = np.std(values_dict[column])\n",
    "        \n",
    "        metrics_summary[\"Metric\"].append(metric)\n",
    "        metrics_summary[\"Column\"].append(column)\n",
    "        metrics_summary[\"Mean Value\"].append(round(mean_val, 2))\n",
    "        metrics_summary[\"Standard Deviation\"].append(round(std_dev, 4))\n",
    "\n",
    "# Convert summary to a DataFrame and display\n",
    "metrics_summary_df = pd.DataFrame(metrics_summary)\n",
    "print(metrics_summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
