{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import miceforest as mf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country                                                   0.00\n",
      "Year                                                      0.00\n",
      "LE_at_birth                                               6.83\n",
      "Doctors_Per_10000                                        67.91\n",
      "Access_to_Electricity                                    47.84\n",
      "Carbon_dioxide_emissions_per_capita_production_tonnes    57.84\n",
      "Gender_Development_Index                                 66.47\n",
      "Gender_Inequality_Index                                  66.50\n",
      "Human_Development_Index                                  61.83\n",
      "Health_Care_Index                                        92.44\n",
      "Crime_Index                                              88.78\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Quality_of_Life_final.csv\")\n",
    "\n",
    "missing_data_percentage = (data.isna().mean() * 100).round(2)\n",
    "\n",
    "print(missing_data_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country                                                   0.00\n",
      "Year                                                      0.00\n",
      "LE_at_birth                                              10.33\n",
      "Doctors_Per_10000                                        63.16\n",
      "Access_to_Electricity                                    18.44\n",
      "Carbon_dioxide_emissions_per_capita_production_tonnes    35.17\n",
      "Gender_Development_Index                                 48.03\n",
      "Gender_Inequality_Index                                  48.27\n",
      "Human_Development_Index                                  41.00\n",
      "Health_Care_Index                                        88.01\n",
      "Crime_Index                                              82.21\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data_1991 = data[data['Year'] >= 1991]\n",
    "\n",
    "null_percentage_1991 = (data_1991.isna().mean() * 100).round(2)\n",
    "\n",
    "print(null_percentage_1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = data_1991[['LE_at_birth', 'Access_to_Electricity', 'Gender_Development_Index','Human_Development_Index','Gender_Inequality_Index']].dropna()\n",
    "\n",
    "base_data.to_csv(\"synthetic_data_healthcare_full.csv\",index = False)\n",
    "\n",
    "np.random.seed(76)\n",
    "remove_percentage = 0.3\n",
    "\n",
    "total_values = base_data.shape[0]\n",
    "num_values_to_remove = int(remove_percentage * total_values)\n",
    "\n",
    "nan_indices_le_at_birth = np.random.choice(base_data.index, num_values_to_remove, replace=False)\n",
    "nan_indices_access_to_electricity = np.random.choice(base_data.index, num_values_to_remove, replace=False)\n",
    "nan_indices_gender_dev_index = np.random.choice(base_data.index, num_values_to_remove, replace=False)\n",
    "nan_indices_human_dev_index = np.random.choice(base_data.index, num_values_to_remove, replace=False)\n",
    "nan_indices_gender_ineq_index = np.random.choice(base_data.index, num_values_to_remove, replace=False)\n",
    "\n",
    "base_data.loc[nan_indices_le_at_birth, 'LE_at_birth'] = np.nan\n",
    "base_data.loc[nan_indices_access_to_electricity, 'Access_to_Electricity'] = np.nan\n",
    "base_data.loc[nan_indices_gender_dev_index, 'Gender_Development_Index'] = np.nan\n",
    "base_data.loc[nan_indices_human_dev_index, 'Human_Development_Index'] = np.nan\n",
    "base_data.loc[nan_indices_gender_ineq_index, 'Gender_Inequality_Index'] = np.nan\n",
    "\n",
    "base_data.to_csv(\"synthetic_data_healthcare.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LE_at_birth</th>\n",
       "      <th>Access_to_Electricity</th>\n",
       "      <th>Gender_Development_Index</th>\n",
       "      <th>Human_Development_Index</th>\n",
       "      <th>Gender_Inequality_Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boosting</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_sample_strategy</th>\n",
       "      <td>bagging</td>\n",
       "      <td>bagging</td>\n",
       "      <td>bagging</td>\n",
       "      <td>bagging</td>\n",
       "      <td>bagging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_iterations</th>\n",
       "      <td>260</td>\n",
       "      <td>301</td>\n",
       "      <td>309</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_sum_hessian_in_leaf</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_gain_to_split</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging_fraction</th>\n",
       "      <td>0.580973</td>\n",
       "      <td>0.501521</td>\n",
       "      <td>0.934758</td>\n",
       "      <td>0.917682</td>\n",
       "      <td>0.484219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_fraction_bynode</th>\n",
       "      <td>0.922566</td>\n",
       "      <td>0.299912</td>\n",
       "      <td>0.412989</td>\n",
       "      <td>0.661024</td>\n",
       "      <td>0.776686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging_freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbosity</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>regression</td>\n",
       "      <td>regression</td>\n",
       "      <td>regression</td>\n",
       "      <td>regression</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        LE_at_birth Access_to_Electricity  \\\n",
       "boosting                       gbdt                  gbdt   \n",
       "data_sample_strategy        bagging               bagging   \n",
       "num_iterations                  260                   301   \n",
       "max_depth                         4                     4   \n",
       "num_leaves                       12                    17   \n",
       "min_data_in_leaf                  4                     6   \n",
       "min_sum_hessian_in_leaf        0.01                  0.01   \n",
       "min_gain_to_split               0.0                   0.0   \n",
       "bagging_fraction           0.580973              0.501521   \n",
       "feature_fraction_bynode    0.922566              0.299912   \n",
       "bagging_freq                      1                     1   \n",
       "verbosity                        -1                    -1   \n",
       "learning_rate                  0.02                  0.02   \n",
       "objective                regression            regression   \n",
       "\n",
       "                        Gender_Development_Index Human_Development_Index  \\\n",
       "boosting                                    gbdt                    gbdt   \n",
       "data_sample_strategy                     bagging                 bagging   \n",
       "num_iterations                               309                     200   \n",
       "max_depth                                      5                       4   \n",
       "num_leaves                                    11                      22   \n",
       "min_data_in_leaf                               2                       9   \n",
       "min_sum_hessian_in_leaf                     0.01                    0.01   \n",
       "min_gain_to_split                            0.0                     0.0   \n",
       "bagging_fraction                        0.934758                0.917682   \n",
       "feature_fraction_bynode                 0.412989                0.661024   \n",
       "bagging_freq                                   1                       1   \n",
       "verbosity                                     -1                      -1   \n",
       "learning_rate                               0.02                    0.02   \n",
       "objective                             regression              regression   \n",
       "\n",
       "                        Gender_Inequality_Index  \n",
       "boosting                                   gbdt  \n",
       "data_sample_strategy                    bagging  \n",
       "num_iterations                              500  \n",
       "max_depth                                     3  \n",
       "num_leaves                                   18  \n",
       "min_data_in_leaf                             48  \n",
       "min_sum_hessian_in_leaf                    0.01  \n",
       "min_gain_to_split                           0.0  \n",
       "bagging_fraction                       0.484219  \n",
       "feature_fraction_bynode                0.776686  \n",
       "bagging_freq                                  1  \n",
       "verbosity                                    -1  \n",
       "learning_rate                              0.02  \n",
       "objective                            regression  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_imputation = pd.read_csv(\"synthetic_data_healthcare.csv\")\n",
    "\n",
    "kernel = mf.ImputationKernel(\n",
    "    data_imputation,\n",
    "    num_datasets = 1,\n",
    "    mean_match_candidates=0,\n",
    "    random_state = 28\n",
    "    )\n",
    "\n",
    "optimal_params = kernel.tune_parameters(\n",
    "    dataset=0, \n",
    "    use_gbdt=True,\n",
    "    num_iterations=500,\n",
    "    random_state=1,\n",
    ")\n",
    "kernel.mice(1, variable_parameters=optimal_params)\n",
    "pd.DataFrame(optimal_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.mice(30,variable_parameters=optimal_params)\n",
    "imputed_data = kernel.complete_data(0)\n",
    "\n",
    "imputed_data.to_csv(\"synthetic_data_healthcare_imputed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Scores:\n",
      "{'LE_at_birth': 0.95, 'Access_to_Electricity': 0.95, 'Gender_Development_Index': 0.9, 'Human_Development_Index': 0.97, 'Gender_Inequality_Index': 0.94}\n",
      "\n",
      "RMSE Scores:\n",
      "{'LE_at_birth': 2.16, 'Access_to_Electricity': 6.82, 'Gender_Development_Index': 0.02, 'Human_Development_Index': 0.03, 'Gender_Inequality_Index': 0.05}\n",
      "\n",
      "MAE Scores:\n",
      "{'LE_at_birth': 0.82, 'Access_to_Electricity': 1.89, 'Gender_Development_Index': 0.01, 'Human_Development_Index': 0.01, 'Gender_Inequality_Index': 0.02}\n"
     ]
    }
   ],
   "source": [
    "synthetic_data_full = pd.read_csv('synthetic_data_healthcare_full.csv')\n",
    "imputed_synthetic_data = pd.read_csv('synthetic_data_healthcare_imputed.csv')\n",
    "\n",
    "columns_to_evaluate = ['LE_at_birth', 'Access_to_Electricity', 'Gender_Development_Index','Human_Development_Index','Gender_Inequality_Index']\n",
    "\n",
    "r2_results = {}\n",
    "rmse_results = {}\n",
    "mae_results = {}\n",
    "\n",
    "for column in columns_to_evaluate:\n",
    "    original_values = synthetic_data_full[column]\n",
    "    imputed_values = imputed_synthetic_data[column]\n",
    "\n",
    "    missing_indices = original_values.isna()\n",
    "    original_values_non_missing = original_values[~missing_indices]\n",
    "    imputed_values_non_missing = imputed_values[~missing_indices]\n",
    "\n",
    "    r2 = r2_score(original_values_non_missing, imputed_values_non_missing)\n",
    "    r2_results[column] = round(r2, 2)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(original_values_non_missing, imputed_values_non_missing))\n",
    "    rmse_results[column] = round(rmse, 2)\n",
    "\n",
    "    mae = mean_absolute_error(original_values_non_missing, imputed_values_non_missing)\n",
    "    mae_results[column] = round(mae, 2)\n",
    "\n",
    "print(\"R² Scores:\")\n",
    "print(r2_results)\n",
    "\n",
    "print(\"\\nRMSE Scores:\")\n",
    "print(rmse_results)\n",
    "\n",
    "print(\"\\nMAE Scores:\")\n",
    "print(mae_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Metric                    Column  Mean Value  Standard Deviation\n",
      "0      R²               LE_at_birth        0.85              0.0098\n",
      "1    RMSE               LE_at_birth        3.54              0.1185\n",
      "2     MAE               LE_at_birth        1.40              0.0435\n",
      "3      R²     Access_to_Electricity        0.87              0.0103\n",
      "4    RMSE     Access_to_Electricity       11.40              0.4365\n",
      "5     MAE     Access_to_Electricity        3.38              0.1456\n",
      "6      R²  Gender_Development_Index        0.78              0.0125\n",
      "7    RMSE  Gender_Development_Index        0.03              0.0009\n",
      "8     MAE  Gender_Development_Index        0.01              0.0004\n",
      "9      R²   Human_Development_Index        0.89              0.0063\n",
      "10   RMSE   Human_Development_Index        0.06              0.0015\n",
      "11    MAE   Human_Development_Index        0.02              0.0006\n",
      "12     R²   Gender_Inequality_Index        0.85              0.0078\n",
      "13   RMSE   Gender_Inequality_Index        0.08              0.0020\n",
      "14    MAE   Gender_Inequality_Index        0.03              0.0007\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "original_data = pd.read_csv('synthetic_data_healthcare_full.csv')\n",
    "\n",
    "columns_to_evaluate = ['LE_at_birth', 'Access_to_Electricity', 'Gender_Development_Index','Human_Development_Index','Gender_Inequality_Index']\n",
    "\n",
    "# Initialize dictionaries to store metrics across iterations\n",
    "r2_results = {col: [] for col in columns_to_evaluate}\n",
    "rmse_results = {col: [] for col in columns_to_evaluate}\n",
    "mae_results = {col: [] for col in columns_to_evaluate}\n",
    "\n",
    "# Parameters for random NaN generation\n",
    "remove_percentage = 0.3\n",
    "num_iterations = 30\n",
    "\n",
    "# Optimal parameters for miceforest\n",
    "optimal_params = {\n",
    "    # Define optimal parameters here\n",
    "}\n",
    "\n",
    "# Run the evaluation over multiple iterations with random NaN values\n",
    "for i in range(num_iterations):\n",
    "    # Create a new copy of the data to introduce NaN values each time\n",
    "    data = original_data.copy()\n",
    "    \n",
    "    # Randomly introduce NaN values in each column for each iteration\n",
    "    for column in columns_to_evaluate:\n",
    "        num_missing = int(remove_percentage * data[column].dropna().shape[0])\n",
    "        nan_indices = random.sample(list(data[column].dropna().index), num_missing)\n",
    "        data.loc[nan_indices, column] = np.nan\n",
    "    \n",
    "    # Initialize the MICE kernel and perform imputation with optimal parameters\n",
    "    kernel = mf.ImputationKernel(data, num_datasets=1, random_state=34)\n",
    "    kernel.mice(1, variable_parameters=optimal_params)\n",
    "    \n",
    "    # Complete the dataset and save it\n",
    "    imputed_data = kernel.complete_data(0)\n",
    "    imputed_data.to_csv(\"synthetic_data_QOLI_imputed.csv\", index=False)\n",
    "    \n",
    "    # Calculate metrics for each column\n",
    "    for column in columns_to_evaluate:\n",
    "        original_values = original_data[column]\n",
    "        imputed_values = imputed_data[column]\n",
    "\n",
    "        # Identify non-missing indices in the original dataset\n",
    "        missing_indices = original_values.isna()\n",
    "        original_values_non_missing = original_values[~missing_indices]\n",
    "        imputed_values_non_missing = imputed_values[~missing_indices]\n",
    "\n",
    "        # R² score\n",
    "        r2 = r2_score(original_values_non_missing, imputed_values_non_missing)\n",
    "        r2_results[column].append(r2)\n",
    "\n",
    "        # RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(original_values_non_missing, imputed_values_non_missing))\n",
    "        rmse_results[column].append(rmse)\n",
    "\n",
    "        # MAE\n",
    "        mae = mean_absolute_error(original_values_non_missing, imputed_values_non_missing)\n",
    "        mae_results[column].append(mae)\n",
    "\n",
    "# Calculate mean and standard deviation of metrics across iterations\n",
    "metrics_summary = {\n",
    "    \"Metric\": [],\n",
    "    \"Column\": [],\n",
    "    \"Mean Value\": [],\n",
    "    \"Standard Deviation\": []\n",
    "}\n",
    "\n",
    "# Aggregate results for R², RMSE, and MAE\n",
    "for column in columns_to_evaluate:\n",
    "    for metric, values_dict in zip([\"R²\", \"RMSE\", \"MAE\"], [r2_results, rmse_results, mae_results]):\n",
    "        mean_val = np.mean(values_dict[column])\n",
    "        std_dev = np.std(values_dict[column])\n",
    "        \n",
    "        metrics_summary[\"Metric\"].append(metric)\n",
    "        metrics_summary[\"Column\"].append(column)\n",
    "        metrics_summary[\"Mean Value\"].append(round(mean_val, 2))\n",
    "        metrics_summary[\"Standard Deviation\"].append(round(std_dev, 4))\n",
    "\n",
    "# Convert summary to a DataFrame and display\n",
    "metrics_summary_df = pd.DataFrame(metrics_summary)\n",
    "print(metrics_summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "synthetic_data = pd.read_csv('synthetic_data_sustainability.csv')\n",
    "full_data = pd.read_csv('synthetic_data_sustainability_full.csv')\n",
    "\n",
    "# Configure and fit the imputer\n",
    "rf_imputer = IterativeImputer(\n",
    "    estimator=RandomForestRegressor(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        min_samples_split=best_params['min_samples_split'],\n",
    "        min_samples_leaf=best_params['min_samples_leaf'],\n",
    "        max_features=best_params['max_features'],\n",
    "        random_state=29\n",
    "    ),\n",
    "    random_state=29\n",
    ")\n",
    "synthetic_data_imputed = pd.DataFrame(rf_imputer.fit_transform(synthetic_data), columns=synthetic_data.columns)\n",
    "\n",
    "# Initialize metrics storage\n",
    "metrics = {'target': [], 'R^2': [], 'RMSE': [], 'MAE': []}\n",
    "missing_columns = synthetic_data.columns[synthetic_data.isnull().any()]\n",
    "\n",
    "# Set up subplots\n",
    "num_columns = len(missing_columns)\n",
    "fig, axes = plt.subplots(nrows=num_columns // 2 + num_columns % 2, ncols=2, figsize=(14, num_columns * 3))\n",
    "axes = axes.flatten()  # Flatten for easy indexing\n",
    "\n",
    "# Loop through each column with missing values\n",
    "for idx, column in enumerate(missing_columns):\n",
    "    y_true = full_data[column]\n",
    "    y_pred = synthetic_data_imputed[column]\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # Append metrics for this target\n",
    "    metrics['target'].append(column)\n",
    "    metrics['R^2'].append(r2)\n",
    "    metrics['RMSE'].append(rmse)\n",
    "    metrics['MAE'].append(mae)\n",
    "    \n",
    "    # Plot distribution comparison in subplots\n",
    "    sns.kdeplot(y_true, label='Original', color='blue', ax=axes[idx])\n",
    "    sns.kdeplot(y_pred, label='Imputed', color='red', ax=axes[idx])\n",
    "    axes[idx].set_title(f\"Distribution of Original vs Imputed for {column}\")\n",
    "    axes[idx].set_xlabel(column)\n",
    "    axes[idx].legend()\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(idx + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display metrics as a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
